{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluating Methodology 1 (Traditional Machine Learning Methods)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Packages"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, \\\n",
    "    classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def evaluateModels(X_train, y_train, models, n_splits):\n",
    "    print(f\"{n_splits}-Fold Cross validation\")\n",
    "    results = []\n",
    "    names = []\n",
    "    for name, model in models:\n",
    "        kfold = model_selection.StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=2)\n",
    "        cv_results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold, scoring='accuracy')\n",
    "        results.append(cv_results)\n",
    "        names.append(name)\n",
    "        print(f\"{name}: Mean Accuracy={cv_results.mean():.5f}, Standard Deviation={cv_results.std():.5f}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Get dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_diff = pd.read_csv('../assets/df_diff')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Preparing dataset (split, scaling and numpy array conversion)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# Separete features and labels\n",
    "df_m1 = df_diff.copy()\n",
    "m1_array = df_m1.values\n",
    "X = m1_array[:, :-1]\n",
    "y = m1_array[:, -1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# normalize features\n",
    "ss = MinMaxScaler()\n",
    "X = ss.fit_transform(X)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# split dataset into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tuning Models before compare"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Logistic Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Hyperparameters : {'C': 0.001, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "Accuracy : 0.565789606521794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "140 fits failed out of a total of 420.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.43421039 0.56578961 0.56578961 0.56578961\n",
      "        nan        nan 0.56578961 0.56578961 0.56578961 0.56578961\n",
      "        nan        nan 0.56578961 0.56578961 0.56578961 0.56578961\n",
      "        nan        nan 0.56507912 0.56258928 0.56223341 0.56223341\n",
      "        nan        nan 0.55725625 0.5561899  0.5561899  0.5561899\n",
      "        nan        nan 0.5561899  0.55583403 0.5561899  0.5561899\n",
      "        nan        nan 0.55583403 0.55583403 0.55583403 0.55583403]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': np.logspace(-3, 3, 7),\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "}\n",
    "\n",
    "logreg = LogisticRegression(max_iter=10000, multi_class='ovr')\n",
    "clf = model_selection.GridSearchCV(logreg,  # model\n",
    "                                   param_grid=parameters,  # hyperparameters\n",
    "                                   scoring='accuracy',  # metric for scoring\n",
    "                                   cv=10)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Tuned Hyperparameters :\", clf.best_params_)\n",
    "print(\"Accuracy :\", clf.best_score_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### SVM"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "tuning models\n",
    "parameters = [\n",
    "    {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "    {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},\n",
    "]\n",
    "svm = SVC()\n",
    "clf = model_selection.GridSearchCV(svm,\n",
    "                                   param_grid=parameters,\n",
    "                                   scoring='accuracy',\n",
    "                                   cv=10)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Tuned Hyperparameters :\", clf.best_params_)\n",
    "print(\"Accuracy :\", clf.best_score_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### KNN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Hyperparameters : {'metric': 'euclidean', 'n_neighbors': 7, 'weights': 'distance'}\n",
      "Accuracy : 0.724758335226269\n"
     ]
    }
   ],
   "source": [
    "# gridsearch for KNN\n",
    "parameters = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11, 13, 15, 17, 19, 21],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "clf = model_selection.GridSearchCV(knn,\n",
    "                                   param_grid=parameters,\n",
    "                                   scoring='accuracy',\n",
    "                                   cv=10)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Tuned Hyperparameters :\", clf.best_params_)\n",
    "print(\"Accuracy :\", clf.best_score_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Naive Bayes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Hyperparameters : {'alpha': 0.1, 'fit_prior': True}\n",
      "Accuracy : 0.565789606521794\n"
     ]
    }
   ],
   "source": [
    "# gridsearch for Naive Bayes\n",
    "parameters = {\n",
    "    'alpha': [0.1, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0],\n",
    "    'fit_prior': [True, False]\n",
    "}\n",
    "\n",
    "nb = MultinomialNB()\n",
    "clf = model_selection.GridSearchCV(nb,\n",
    "                                   param_grid=parameters,\n",
    "                                   scoring='accuracy',\n",
    "                                   cv=10)\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Tuned Hyperparameters :\", clf.best_params_)\n",
    "print(\"Accuracy :\", clf.best_score_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Compare Models using 10-fold cross validation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "models = []\n",
    "\n",
    "models.append(('LR', LogisticRegression(max_iter=10000, multi_class='ovr', C=0.001, penalty='l2', solver='newton-cg')))\n",
    "models.append(('SVM', SVC(C=1, kernel='linear')))\n",
    "models.append(('KNN', KNeighborsClassifier(metric='euclidean', n_neighbors=7, weights='distance')))\n",
    "models.append(('NB', MultinomialNB(alpha=0.1, fit_prior=True)))\n",
    "\n",
    "evaluateModels(X_train, y_train, models, 10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Predictions with best model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.63      0.78      0.70       305\n",
      "         1.0       0.79      0.65      0.72       398\n",
      "\n",
      "    accuracy                           0.71       703\n",
      "   macro avg       0.71      0.72      0.71       703\n",
      "weighted avg       0.72      0.71      0.71       703\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model = KNeighborsClassifier(metric='euclidean', n_neighbors=7, weights='distance')\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
