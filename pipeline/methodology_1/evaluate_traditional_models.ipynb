{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluating Methodology 1 (Traditional Machine Learning Methods)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Packages"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, \\\n",
    "    classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def evaluateModels(X_train, y_train, models, n_splits):\n",
    "    print(f\"{n_splits}-Fold Cross validation\")\n",
    "    results = []\n",
    "    names = []\n",
    "    for name, model in models:\n",
    "        kfold = model_selection.StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=2)\n",
    "        cv_results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold, scoring='accuracy')\n",
    "        results.append(cv_results)\n",
    "        names.append(name)\n",
    "        print(f\"{name}: Mean Accuracy={cv_results.mean():.5f}, Standard Deviation={cv_results.std():.5f}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Get dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "      diff_read0  diff_read1  diff_read2  diff_read3  diff_read4  diff_read5  \\\n0           0.22       -0.86        0.43        0.04       -0.86       -0.19   \n1           0.21        0.15        0.08        0.30       -0.15        0.11   \n2           0.32        0.15        0.08       -0.02        0.03        0.11   \n3           0.05        0.13        0.34        0.53        0.55        0.51   \n4           0.16        0.42        0.46        0.48        0.44        0.41   \n...          ...         ...         ...         ...         ...         ...   \n3510       -1.35       -1.34       -1.34       -1.35       -1.35       -1.34   \n3511       -1.29       -1.52       -1.45       -1.44       -1.46       -1.45   \n3512       -1.23       -1.30       -1.29       -1.29       -1.27       -1.29   \n3513       -1.09       -1.41       -1.43       -1.42       -1.41       -1.43   \n3514       -1.42       -1.42       -1.41       -1.42       -1.41       -1.40   \n\n      diff_read6  diff_read7  diff_read8  diff_read9   mean  start_timestamp  \\\n0          -0.33        0.05        0.23       -0.18 -0.145       1665656955   \n1           0.09       -0.10        0.03       -0.19  0.053       1665656968   \n2          -0.27        0.06       -0.04        0.57  0.099       1665656982   \n3           0.43        0.33        0.28        0.37  0.352       1665656914   \n4          -0.17       -0.29        0.34        0.34  0.259       1665656928   \n...          ...         ...         ...         ...    ...              ...   \n3510       -1.35       -1.37       -1.35       -1.36 -1.350       1674811711   \n3511       -1.45       -1.20        0.47       -0.92 -1.171       1674811725   \n3512       -1.28       -1.28       -1.28       -0.27 -1.178       1674811654   \n3513       -1.42       -1.42       -1.42       -1.42 -1.387       1674811669   \n3514       -1.37       -1.36       -1.34       -1.31 -1.386       1674811683   \n\n      end_timestamp  diff_timestemp  inference  \n0        1665656967              12          1  \n1        1665656980              12          1  \n2        1665656994              12          1  \n3        1665656926              12          1  \n4        1665656940              12          1  \n...             ...             ...        ...  \n3510     1674811723              12          0  \n3511     1674811737              12          1  \n3512     1674811667              13          1  \n3513     1674811681              12          1  \n3514     1674811695              12          0  \n\n[3515 rows x 15 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>diff_read0</th>\n      <th>diff_read1</th>\n      <th>diff_read2</th>\n      <th>diff_read3</th>\n      <th>diff_read4</th>\n      <th>diff_read5</th>\n      <th>diff_read6</th>\n      <th>diff_read7</th>\n      <th>diff_read8</th>\n      <th>diff_read9</th>\n      <th>mean</th>\n      <th>start_timestamp</th>\n      <th>end_timestamp</th>\n      <th>diff_timestemp</th>\n      <th>inference</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.22</td>\n      <td>-0.86</td>\n      <td>0.43</td>\n      <td>0.04</td>\n      <td>-0.86</td>\n      <td>-0.19</td>\n      <td>-0.33</td>\n      <td>0.05</td>\n      <td>0.23</td>\n      <td>-0.18</td>\n      <td>-0.145</td>\n      <td>1665656955</td>\n      <td>1665656967</td>\n      <td>12</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.21</td>\n      <td>0.15</td>\n      <td>0.08</td>\n      <td>0.30</td>\n      <td>-0.15</td>\n      <td>0.11</td>\n      <td>0.09</td>\n      <td>-0.10</td>\n      <td>0.03</td>\n      <td>-0.19</td>\n      <td>0.053</td>\n      <td>1665656968</td>\n      <td>1665656980</td>\n      <td>12</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.32</td>\n      <td>0.15</td>\n      <td>0.08</td>\n      <td>-0.02</td>\n      <td>0.03</td>\n      <td>0.11</td>\n      <td>-0.27</td>\n      <td>0.06</td>\n      <td>-0.04</td>\n      <td>0.57</td>\n      <td>0.099</td>\n      <td>1665656982</td>\n      <td>1665656994</td>\n      <td>12</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.05</td>\n      <td>0.13</td>\n      <td>0.34</td>\n      <td>0.53</td>\n      <td>0.55</td>\n      <td>0.51</td>\n      <td>0.43</td>\n      <td>0.33</td>\n      <td>0.28</td>\n      <td>0.37</td>\n      <td>0.352</td>\n      <td>1665656914</td>\n      <td>1665656926</td>\n      <td>12</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.16</td>\n      <td>0.42</td>\n      <td>0.46</td>\n      <td>0.48</td>\n      <td>0.44</td>\n      <td>0.41</td>\n      <td>-0.17</td>\n      <td>-0.29</td>\n      <td>0.34</td>\n      <td>0.34</td>\n      <td>0.259</td>\n      <td>1665656928</td>\n      <td>1665656940</td>\n      <td>12</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3510</th>\n      <td>-1.35</td>\n      <td>-1.34</td>\n      <td>-1.34</td>\n      <td>-1.35</td>\n      <td>-1.35</td>\n      <td>-1.34</td>\n      <td>-1.35</td>\n      <td>-1.37</td>\n      <td>-1.35</td>\n      <td>-1.36</td>\n      <td>-1.350</td>\n      <td>1674811711</td>\n      <td>1674811723</td>\n      <td>12</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3511</th>\n      <td>-1.29</td>\n      <td>-1.52</td>\n      <td>-1.45</td>\n      <td>-1.44</td>\n      <td>-1.46</td>\n      <td>-1.45</td>\n      <td>-1.45</td>\n      <td>-1.20</td>\n      <td>0.47</td>\n      <td>-0.92</td>\n      <td>-1.171</td>\n      <td>1674811725</td>\n      <td>1674811737</td>\n      <td>12</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3512</th>\n      <td>-1.23</td>\n      <td>-1.30</td>\n      <td>-1.29</td>\n      <td>-1.29</td>\n      <td>-1.27</td>\n      <td>-1.29</td>\n      <td>-1.28</td>\n      <td>-1.28</td>\n      <td>-1.28</td>\n      <td>-0.27</td>\n      <td>-1.178</td>\n      <td>1674811654</td>\n      <td>1674811667</td>\n      <td>13</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3513</th>\n      <td>-1.09</td>\n      <td>-1.41</td>\n      <td>-1.43</td>\n      <td>-1.42</td>\n      <td>-1.41</td>\n      <td>-1.43</td>\n      <td>-1.42</td>\n      <td>-1.42</td>\n      <td>-1.42</td>\n      <td>-1.42</td>\n      <td>-1.387</td>\n      <td>1674811669</td>\n      <td>1674811681</td>\n      <td>12</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3514</th>\n      <td>-1.42</td>\n      <td>-1.42</td>\n      <td>-1.41</td>\n      <td>-1.42</td>\n      <td>-1.41</td>\n      <td>-1.40</td>\n      <td>-1.37</td>\n      <td>-1.36</td>\n      <td>-1.34</td>\n      <td>-1.31</td>\n      <td>-1.386</td>\n      <td>1674811683</td>\n      <td>1674811695</td>\n      <td>12</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>3515 rows × 15 columns</p>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_diff = pd.read_csv('../../assets/df_diff.csv', index_col=0)\n",
    "df_diff\n",
    "\n",
    "# example of read_csv on google drive\n",
    "# df_diff = pd.read_csv('/content/drive/MyDrive/Empresas/ZRP/Desafio Técnico/zrp_case-main/assets/df_diff.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Preparing dataset (split, scaling and numpy array conversion)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# Separete features and labels\n",
    "df_m1 = df_diff.copy()\n",
    "m1_array = df_m1.values\n",
    "X = m1_array[:, :-1]\n",
    "y = m1_array[:, -1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "# normalize features\n",
    "ss = MinMaxScaler()\n",
    "X = ss.fit_transform(X)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# split dataset into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tuning Models before compare\n",
    "\n",
    "The motivation for this section is to find the best hyperparameters for each model, so that the best model can be chosen."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Logistic Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Hyperparameters : {'C': 1.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Accuracy : 0.5807337018247899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "140 fits failed out of a total of 420.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.43421039 0.56578961 0.56578961 0.56578961\n",
      "        nan        nan 0.56578961 0.56578961 0.56578961 0.56294263\n",
      "        nan        nan 0.56472199 0.5721953  0.5721953  0.57788546\n",
      "        nan        nan 0.5807337  0.57362131 0.57397718 0.57468514\n",
      "        nan        nan 0.57718003 0.57753464 0.57753464 0.5768229\n",
      "        nan        nan 0.57753338 0.5768229  0.5768229  0.5768229\n",
      "        nan        nan 0.5768229  0.5768229  0.5768229  0.5768229 ]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': np.logspace(-3, 3, 7),\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "}\n",
    "\n",
    "logreg = LogisticRegression(max_iter=10000, multi_class='ovr')\n",
    "clf = model_selection.GridSearchCV(logreg,  # model\n",
    "                                   param_grid=parameters,  # hyperparameters\n",
    "                                   scoring='accuracy',  # metric for scoring\n",
    "                                   cv=10)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Tuned Hyperparameters :\", clf.best_params_)\n",
    "print(\"Accuracy :\", clf.best_score_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### SVM"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Hyperparameters : {'C': 1, 'kernel': 'linear'}\n",
      "Accuracy : 0.565789606521794\n"
     ]
    }
   ],
   "source": [
    "\n",
    "parameters = [\n",
    "    {'C': [1, 10], 'kernel': ['linear']},\n",
    "    {'C': [1, 10], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},\n",
    "]\n",
    "svm = SVC()\n",
    "clf = model_selection.GridSearchCV(svm,\n",
    "                                   param_grid=parameters,\n",
    "                                   scoring='accuracy',\n",
    "                                   cv=10)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Tuned Hyperparameters :\", clf.best_params_)\n",
    "print(\"Accuracy :\", clf.best_score_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### KNN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Hyperparameters : {'metric': 'euclidean', 'n_neighbors': 7, 'weights': 'distance'}\n",
      "Accuracy : 0.7258044976149012\n"
     ]
    }
   ],
   "source": [
    "# gridsearch for KNN\n",
    "parameters = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11, 13, 15, 17, 19, 21],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "clf = model_selection.GridSearchCV(knn,\n",
    "                                   param_grid=parameters,\n",
    "                                   scoring='accuracy',\n",
    "                                   cv=10)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Tuned Hyperparameters :\", clf.best_params_)\n",
    "print(\"Accuracy :\", clf.best_score_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Naive Bayes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Hyperparameters : {'alpha': 0.1, 'fit_prior': True}\n",
      "Accuracy : 0.565789606521794\n"
     ]
    }
   ],
   "source": [
    "# gridsearch for Naive Bayes\n",
    "parameters = {\n",
    "    'alpha': [0.1, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0],\n",
    "    'fit_prior': [True, False]\n",
    "}\n",
    "\n",
    "nb = MultinomialNB()\n",
    "clf = model_selection.GridSearchCV(nb,\n",
    "                                   param_grid=parameters,\n",
    "                                   scoring='accuracy',\n",
    "                                   cv=10)\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Tuned Hyperparameters :\", clf.best_params_)\n",
    "print(\"Accuracy :\", clf.best_score_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Compare Models using 10-fold cross validation\n",
    "Cross validation is very important to evaluate the performance of models in a fair way. Besides that, it is very used on literature."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-Fold Cross validation\n",
      "LR: Mean Accuracy=0.56579, Standard Deviation=0.00080\n",
      "SVM: Mean Accuracy=0.56579, Standard Deviation=0.00080\n",
      "KNN: Mean Accuracy=0.72688, Standard Deviation=0.03226\n",
      "NB: Mean Accuracy=0.56579, Standard Deviation=0.00080\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "\n",
    "models.append(('LR', LogisticRegression(max_iter=10000, multi_class='ovr', C=0.001, penalty='l2', solver='newton-cg')))\n",
    "models.append(('SVM', SVC(C=1, kernel='linear')))\n",
    "models.append(('KNN', KNeighborsClassifier(metric='euclidean', n_neighbors=7, weights='distance')))\n",
    "models.append(('NB', MultinomialNB(alpha=0.1, fit_prior=True)))\n",
    "\n",
    "evaluateModels(X_train, y_train, models, 10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Notes**:\n",
    "Based on the results above, can be said that the best model is KNN with 7 neighbors, using euclidean distance and distance as weights.\n",
    "\n",
    "The prediction with test data will be made on the apply_traditional_model.ipyb notebook."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
